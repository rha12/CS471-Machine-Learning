{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries and functions"
      ],
      "metadata": {
        "id": "MFtv5Myzu_Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the MNIST dataset from Keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Import the to_categorical function from Keras\n",
        "# to convert the labels to one-hot encoded vectors\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Import the Sequential class from Keras\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Import the Dense class from Keras\n",
        "# to add fully connected layers to the neural network\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Import the matplotlib.pyplot library for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import the NumPy library for numerical operations\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hsfr4illurh3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and preprocess the MNIST dataset using Python."
      ],
      "metadata": {
        "id": "UAWJD5qtvNDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.reshape(-1, 784) / 255.0\n",
        "X_test = X_test.reshape(-1, 784) / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "RQU2gdbpFByN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a neural network using Python and NumPy with \n",
        "* Different activation functions i.e., sigmoid, ReLu and hyperbolic tangent (tanh) function on hidden layers and softmax on output layer. \n",
        "* Different sizes of hidden layers i.e., 32, 64, 128 and 256.  \n",
        "* Use accuracy as evaluation metric. \n"
      ],
      "metadata": {
        "id": "WdaQ24c9vR--"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6kTAhl8XCWYI"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "def build_model(hidden_sizes, activation_functions):\n",
        "    model = Sequential()\n",
        "    for i in range(len(hidden_sizes)):\n",
        "        if i == 0:\n",
        "            model.add(Dense(hidden_sizes[i], activation=activation_functions[i], input_shape=(784,)))\n",
        "        else:\n",
        "            model.add(Dense(hidden_sizes[i], activation=activation_functions[i]))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and evaluate the performance of the neural network. \n",
        "# Save the best performing network model using model.save() method. "
      ],
      "metadata": {
        "id": "MwJBNoN0v56F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters\n",
        "hidden_sizes = [32, 64, 128, 256]\n",
        "activation_functions = ['sigmoid', 'relu', 'tanh']\n",
        "\n",
        "# Train and evaluate the model for each combination of hyperparameters\n",
        "best_accuracy = 0\n",
        "accuracies = np.zeros((len(hidden_sizes), len(activation_functions)))\n",
        "for i, size in enumerate(hidden_sizes):\n",
        "    for j, func in enumerate(activation_functions):\n",
        "        model = build_model([size, size], [func, func])\n",
        "        model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1, validation_data=(X_test, y_test))\n",
        "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f\"Size: {size}, Activation Function: {func}, Test Accuracy: {accuracy}\")\n",
        "        accuracies[i, j] = accuracy\n",
        "        if accuracy > best_accuracy:\n",
        "            best_model = model\n",
        "            best_accuracy = accuracy\n",
        "\n",
        "# Save the best model to disk\n",
        "best_model.save(\"best_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzGORHv0wE88",
        "outputId": "dd7a553f-fb6a-4268-b1ea-8238315d8d80"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 4s 6ms/step - loss: 1.3225 - accuracy: 0.7210 - val_loss: 0.6349 - val_accuracy: 0.8717\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4752 - accuracy: 0.8898 - val_loss: 0.3673 - val_accuracy: 0.9047\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3273 - accuracy: 0.9126 - val_loss: 0.2867 - val_accuracy: 0.9206\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2650 - accuracy: 0.9273 - val_loss: 0.2430 - val_accuracy: 0.9313\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2262 - accuracy: 0.9376 - val_loss: 0.2148 - val_accuracy: 0.9397\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1984 - accuracy: 0.9442 - val_loss: 0.1921 - val_accuracy: 0.9453\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1767 - accuracy: 0.9501 - val_loss: 0.1779 - val_accuracy: 0.9489\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9550 - val_loss: 0.1652 - val_accuracy: 0.9531\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1463 - accuracy: 0.9585 - val_loss: 0.1582 - val_accuracy: 0.9543\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1353 - accuracy: 0.9617 - val_loss: 0.1489 - val_accuracy: 0.9555\n",
            "Size: 32, Activation Function: sigmoid, Test Accuracy: 0.9555000066757202\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4819 - accuracy: 0.8670 - val_loss: 0.2517 - val_accuracy: 0.9275\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2250 - accuracy: 0.9355 - val_loss: 0.1908 - val_accuracy: 0.9442\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1759 - accuracy: 0.9484 - val_loss: 0.1594 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1474 - accuracy: 0.9566 - val_loss: 0.1471 - val_accuracy: 0.9554\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1276 - accuracy: 0.9621 - val_loss: 0.1303 - val_accuracy: 0.9594\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1139 - accuracy: 0.9661 - val_loss: 0.1260 - val_accuracy: 0.9623\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1020 - accuracy: 0.9692 - val_loss: 0.1177 - val_accuracy: 0.9650\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0942 - accuracy: 0.9723 - val_loss: 0.1133 - val_accuracy: 0.9653\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9737 - val_loss: 0.1029 - val_accuracy: 0.9685\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9757 - val_loss: 0.1076 - val_accuracy: 0.9679\n",
            "Size: 32, Activation Function: relu, Test Accuracy: 0.9678999781608582\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.4933 - accuracy: 0.8718 - val_loss: 0.2604 - val_accuracy: 0.9256\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2284 - accuracy: 0.9350 - val_loss: 0.1953 - val_accuracy: 0.9439\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1758 - accuracy: 0.9492 - val_loss: 0.1710 - val_accuracy: 0.9504\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1469 - accuracy: 0.9568 - val_loss: 0.1500 - val_accuracy: 0.9566\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9631 - val_loss: 0.1355 - val_accuracy: 0.9609\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1115 - accuracy: 0.9679 - val_loss: 0.1333 - val_accuracy: 0.9606\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0996 - accuracy: 0.9704 - val_loss: 0.1289 - val_accuracy: 0.9605\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9730 - val_loss: 0.1277 - val_accuracy: 0.9632\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9752 - val_loss: 0.1262 - val_accuracy: 0.9626\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9773 - val_loss: 0.1232 - val_accuracy: 0.9634\n",
            "Size: 32, Activation Function: tanh, Test Accuracy: 0.9634000062942505\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.9295 - accuracy: 0.7909 - val_loss: 0.3769 - val_accuracy: 0.9050\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3083 - accuracy: 0.9170 - val_loss: 0.2500 - val_accuracy: 0.9296\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2278 - accuracy: 0.9351 - val_loss: 0.2043 - val_accuracy: 0.9399\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1855 - accuracy: 0.9469 - val_loss: 0.1738 - val_accuracy: 0.9475\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1574 - accuracy: 0.9542 - val_loss: 0.1536 - val_accuracy: 0.9545\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1350 - accuracy: 0.9605 - val_loss: 0.1379 - val_accuracy: 0.9582\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1171 - accuracy: 0.9657 - val_loss: 0.1243 - val_accuracy: 0.9628\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1037 - accuracy: 0.9699 - val_loss: 0.1164 - val_accuracy: 0.9638\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0920 - accuracy: 0.9733 - val_loss: 0.1079 - val_accuracy: 0.9653\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0822 - accuracy: 0.9761 - val_loss: 0.1012 - val_accuracy: 0.9670\n",
            "Size: 64, Activation Function: sigmoid, Test Accuracy: 0.9670000076293945\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.3910 - accuracy: 0.8889 - val_loss: 0.1868 - val_accuracy: 0.9449\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1638 - accuracy: 0.9523 - val_loss: 0.1435 - val_accuracy: 0.9570\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1224 - accuracy: 0.9635 - val_loss: 0.1142 - val_accuracy: 0.9651\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0979 - accuracy: 0.9705 - val_loss: 0.1012 - val_accuracy: 0.9690\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0827 - accuracy: 0.9750 - val_loss: 0.1043 - val_accuracy: 0.9683\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0696 - accuracy: 0.9792 - val_loss: 0.0924 - val_accuracy: 0.9710\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0595 - accuracy: 0.9821 - val_loss: 0.0840 - val_accuracy: 0.9740\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0516 - accuracy: 0.9841 - val_loss: 0.0925 - val_accuracy: 0.9727\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0442 - accuracy: 0.9868 - val_loss: 0.0926 - val_accuracy: 0.9731\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0904 - val_accuracy: 0.9724\n",
            "Size: 64, Activation Function: relu, Test Accuracy: 0.9724000096321106\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.3932 - accuracy: 0.8917 - val_loss: 0.2211 - val_accuracy: 0.9349\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1862 - accuracy: 0.9450 - val_loss: 0.1570 - val_accuracy: 0.9536\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1335 - accuracy: 0.9610 - val_loss: 0.1292 - val_accuracy: 0.9599\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1033 - accuracy: 0.9699 - val_loss: 0.1116 - val_accuracy: 0.9667\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0830 - accuracy: 0.9756 - val_loss: 0.1002 - val_accuracy: 0.9704\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0690 - accuracy: 0.9792 - val_loss: 0.0904 - val_accuracy: 0.9721\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0571 - accuracy: 0.9828 - val_loss: 0.0985 - val_accuracy: 0.9709\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 0.0870 - val_accuracy: 0.9752\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.0838 - val_accuracy: 0.9748\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0852 - val_accuracy: 0.9751\n",
            "Size: 64, Activation Function: tanh, Test Accuracy: 0.9750999808311462\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 9ms/step - loss: 0.7062 - accuracy: 0.8235 - val_loss: 0.2823 - val_accuracy: 0.9208\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.2466 - accuracy: 0.9288 - val_loss: 0.2077 - val_accuracy: 0.9382\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1866 - accuracy: 0.9445 - val_loss: 0.1691 - val_accuracy: 0.9499\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1485 - accuracy: 0.9562 - val_loss: 0.1387 - val_accuracy: 0.9572\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1216 - accuracy: 0.9640 - val_loss: 0.1199 - val_accuracy: 0.9636\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1001 - accuracy: 0.9710 - val_loss: 0.1064 - val_accuracy: 0.9673\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0844 - accuracy: 0.9759 - val_loss: 0.0951 - val_accuracy: 0.9692\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0713 - accuracy: 0.9794 - val_loss: 0.0981 - val_accuracy: 0.9692\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0603 - accuracy: 0.9826 - val_loss: 0.0827 - val_accuracy: 0.9729\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0516 - accuracy: 0.9850 - val_loss: 0.0857 - val_accuracy: 0.9733\n",
            "Size: 128, Activation Function: sigmoid, Test Accuracy: 0.9732999801635742\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3151 - accuracy: 0.9094 - val_loss: 0.1564 - val_accuracy: 0.9527\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1264 - accuracy: 0.9633 - val_loss: 0.1204 - val_accuracy: 0.9641\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0896 - accuracy: 0.9728 - val_loss: 0.0923 - val_accuracy: 0.9702\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0665 - accuracy: 0.9802 - val_loss: 0.0810 - val_accuracy: 0.9752\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0510 - accuracy: 0.9841 - val_loss: 0.0741 - val_accuracy: 0.9775\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.0813 - val_accuracy: 0.9760\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0797 - val_accuracy: 0.9759\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.0844 - val_accuracy: 0.9737\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0867 - val_accuracy: 0.9762\n",
            "Size: 128, Activation Function: relu, Test Accuracy: 0.9761999845504761\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3300 - accuracy: 0.9044 - val_loss: 0.1875 - val_accuracy: 0.9418\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1534 - accuracy: 0.9546 - val_loss: 0.1347 - val_accuracy: 0.9590\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1052 - accuracy: 0.9686 - val_loss: 0.1096 - val_accuracy: 0.9671\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0931 - val_accuracy: 0.9699\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0612 - accuracy: 0.9817 - val_loss: 0.0844 - val_accuracy: 0.9726\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0479 - accuracy: 0.9858 - val_loss: 0.0758 - val_accuracy: 0.9764\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.0759 - val_accuracy: 0.9762\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 0.0756 - val_accuracy: 0.9759\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0848 - val_accuracy: 0.9741\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.0774 - val_accuracy: 0.9764\n",
            "Size: 128, Activation Function: tanh, Test Accuracy: 0.9764000177383423\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 9ms/step - loss: 0.5754 - accuracy: 0.8447 - val_loss: 0.2522 - val_accuracy: 0.9239\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2234 - accuracy: 0.9342 - val_loss: 0.1803 - val_accuracy: 0.9444\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1678 - accuracy: 0.9498 - val_loss: 0.1588 - val_accuracy: 0.9520\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1304 - accuracy: 0.9612 - val_loss: 0.1201 - val_accuracy: 0.9628\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1010 - accuracy: 0.9702 - val_loss: 0.1028 - val_accuracy: 0.9680\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0818 - accuracy: 0.9752 - val_loss: 0.0947 - val_accuracy: 0.9699\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0673 - accuracy: 0.9801 - val_loss: 0.0832 - val_accuracy: 0.9738\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0540 - accuracy: 0.9837 - val_loss: 0.0767 - val_accuracy: 0.9754\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 0.0757 - val_accuracy: 0.9770\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0677 - val_accuracy: 0.9789\n",
            "Size: 256, Activation Function: sigmoid, Test Accuracy: 0.9789000153541565\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 6s 10ms/step - loss: 0.2564 - accuracy: 0.9265 - val_loss: 0.1174 - val_accuracy: 0.9633\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0938 - accuracy: 0.9716 - val_loss: 0.0845 - val_accuracy: 0.9730\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0622 - accuracy: 0.9809 - val_loss: 0.0808 - val_accuracy: 0.9762\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.0643 - val_accuracy: 0.9801\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0330 - accuracy: 0.9897 - val_loss: 0.0826 - val_accuracy: 0.9761\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.0846 - val_accuracy: 0.9767\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.0800 - val_accuracy: 0.9790\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0806 - val_accuracy: 0.9790\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.1044 - val_accuracy: 0.9720\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0887 - val_accuracy: 0.9780\n",
            "Size: 256, Activation Function: relu, Test Accuracy: 0.9779999852180481\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 8ms/step - loss: 0.2934 - accuracy: 0.9145 - val_loss: 0.1583 - val_accuracy: 0.9537\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1360 - accuracy: 0.9595 - val_loss: 0.1120 - val_accuracy: 0.9651\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0905 - accuracy: 0.9729 - val_loss: 0.0954 - val_accuracy: 0.9705\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0672 - accuracy: 0.9791 - val_loss: 0.0793 - val_accuracy: 0.9749\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0496 - accuracy: 0.9842 - val_loss: 0.0700 - val_accuracy: 0.9771\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 0.0734 - val_accuracy: 0.9771\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0717 - val_accuracy: 0.9785\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.0681 - val_accuracy: 0.9793\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.0655 - val_accuracy: 0.9792\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0639 - val_accuracy: 0.9810\n",
            "Size: 256, Activation Function: tanh, Test Accuracy: 0.9810000061988831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare and visualize the results of the neural network"
      ],
      "metadata": {
        "id": "T7LHiRI6wHxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a heatmap of the test accuracies\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(accuracies, cmap='viridis')\n",
        "ax.set_xticks(np.arange(len(activation_functions)))\n",
        "ax.set_yticks(np.arange(len(hidden_sizes)))\n",
        "ax.set_xticklabels(activation_functions)\n",
        "ax.set_yticklabels(hidden_sizes)\n",
        "ax.set_xlabel(\"Activation Function\")\n",
        "ax.set_ylabel(\"Hidden Layer Size\")\n",
        "ax.set_title(\"Test Accuracy by Hidden Layer Size and Activation Function\")\n",
        "plt.colorbar(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IsRBgHaWwJhi",
        "outputId": "3462fc10-590f-45bf-9552-9fb20575335d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
